{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качаем датасет (команды, перед которыми стоит восклицательный знак, выполняются в консоли)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.deeppavlov.ai/datasets/snips_intents/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем его библиотекой pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Add another song to the Cita RomГЎntica playli...</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add clem burke in my playlist Pre-Party R&amp;B Jams</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add Live from Aragon Ballroom to Trapeo</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add Unite and Win to my night out</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Add track to my Digster Future Hits</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        intents\n",
       "0  Add another song to the Cita RomГЎntica playli...  AddToPlaylist\n",
       "1   add clem burke in my playlist Pre-Party R&B Jams  AddToPlaylist\n",
       "2            Add Live from Aragon Ballroom to Trapeo  AddToPlaylist\n",
       "3                  add Unite and Win to my night out  AddToPlaylist\n",
       "4                Add track to my Digster Future Hits  AddToPlaylist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только тексты и интенты. Ничего лишнего. \n",
    "\n",
    "Сколько всего данных и как распределены интенты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего данных: 15884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GetWeather              2300\n",
       "PlayMusic               2300\n",
       "BookRestaurant          2273\n",
       "SearchScreeningEvent    2259\n",
       "RateBook                2256\n",
       "SearchCreativeWork      2254\n",
       "AddToPlaylist           2242\n",
       "Name: intents, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Всего данных: {data.shape[0]}')\n",
    "\n",
    "data['intents'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "преобразуем названия интентов в числа от 0 до 6 и положим эти метки классов в отдельный столбец target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['intents'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиваем датасет на обучающий и тестовый\n",
    "\n",
    "Обычно задачи в машинном обучении поставлены как \"обучиться на имеющихся данных, чтобы потом работать с новыми\". \n",
    "\n",
    "Но конкретно сейчас у нас нет этих самых новых данных, поэтому мы разделим имеющийся датасет на две части. На одной будем учить модели, на другой -- проверять. \n",
    "\n",
    "*на самом деле, данные почти всегда делят на обучающую, валидационную и тестовую подвыборки, валидационную используют для промежуточной проверки модели и настройки параметров, которые невозможно настроить в ходе обучения модели (скажем, архитектура модели, критерии завершения итерационного алгоритма обучения, степень интерполяционного полинома, количество моделей в ансамбле и тд). Также существует перекрестная проверка (кросс-валидация), когда модель обучается и проверяется несколько раз на разном разбиении выборки на обучающую и валидационную (тестовую подвыборку при этом не трогают).           \n",
    "Но в данном примере мы обойдемся очень простым подходом*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(data, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простое решение: tf-idf/logreg\n",
    "\n",
    "Общая идея у всех подходов одна и та же: \n",
    "\n",
    "1. Мы каким-то образом преобразуем тексты в числовые вектора одинаковой длины\n",
    "2. На получившейся выборке числовых векторов обучаем модель. \n",
    "\n",
    "Конкретно сейчас для преобразования текстов в вектора мы будем использовать tf-idf. Суть этого подхода вкратце:\n",
    "\n",
    "* мы игнорируем порядок слов в предложении\n",
    "* составляем словарь всех слов из всех предложений\n",
    "* для каждого предложения считаем количество вхождений всех слов из словаря. Получим длинный вектор, в котором большинство значений будут нулями. Поэтому, кстати, для хранения итоговой матрицы объектов-признаков используется sparse-формат (разреженная матрица, когда мы просто перечисляем ненулевые элементы и их позиции, а не храним всю матрицу в памяти явно). \n",
    "* для каждого слова делим все его посчитанные вхождения на частоту встречаемости этого слова в различных текстах.\n",
    "\n",
    "*Тут проще пояснить на примере.      \n",
    "Допустим, мы векторизуем таким образом большое количество научных статей. У статей по математике слово \"интеграл\" будет встречаться довольно часто (а среди всех статей оно будет довольно редким), поэтому итоговый \"вес\" этого слова в векторах будет довольно большим. Аналогично, например, с биологией и словом \"хромосома\".    \n",
    "А слова, которые встречаются часто в самых разных статьях (например, слово \"следовательно\" или какой-нибудь предлог) будут получать меньший \"вес\". Аналогично со словами, которые встречаются очень редко -- например, в какой-то статье предлагается новый метод, авторы которого его как-то назвали. Если статья новая, то это название будет встречаться только в ней (в векторе, соответствующем этой статье вес этого слова будет очень большим, во всех остальных -- нулевой)*\n",
    "\n",
    "Алгоритм tf-idf очень легко реализуется на python, но мы сейчас этого делать не будем, используем готовую реализацию из scikit-learn. \n",
    "\n",
    "Но сперва данные нужно будет дополнительно предобработать, тк в них есть слова в разных регистрах (слова 'add' и 'Add' с точки зрения компьютера -- разные) и разных формах. \n",
    "\n",
    "Предобработку тут сделаем простую: \n",
    "\n",
    "1. приведение к нижнему регистру и лемматизация\n",
    "2. удаление знаков препинания и стопслов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_parser = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokenized_text = spacy_parser(text)\n",
    "    \n",
    "    processed_text = []\n",
    "    for token in tokenized_text:\n",
    "        if not token.is_stop and token.pos_ != 'PUNCT':\n",
    "            processed_text.append(token.lemma_)\n",
    "    \n",
    "    return ' '.join(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка текстов может длиться ощутимое время, поэтому сразу заводим прогресс-бар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()  # включаем совместимость с pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99adf35792ad4f4a9866be9b699a42c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/demo_intents/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603ff69cf91348fa9150f26d374d196e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/demo_intents/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_test['processed_text'] = data_test['text'].progress_apply(preprocess_text)\n",
    "data_train['processed_text'] = data_train['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intents</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10083</th>\n",
       "      <td>play the game Piety Street</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>5</td>\n",
       "      <td>play game piety street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>Is it chilly in Curacao</td>\n",
       "      <td>GetWeather</td>\n",
       "      <td>2</td>\n",
       "      <td>be chilly curacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>add Dean Martin track to metal xplorer playlist</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>0</td>\n",
       "      <td>add dean martin track metal xplorer playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Add another tune to my Soft Rock  playlist.</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>0</td>\n",
       "      <td>add tune soft rock   playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>Is it going to get windy today in Tunisia?</td>\n",
       "      <td>GetWeather</td>\n",
       "      <td>2</td>\n",
       "      <td>be go windy today tunisia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text             intents  \\\n",
       "10083                       play the game Piety Street  SearchCreativeWork   \n",
       "4872                          Is it chilly in Curacao           GetWeather   \n",
       "447    add Dean Martin track to metal xplorer playlist       AddToPlaylist   \n",
       "1791      Add another tune to my Soft Rock  playlist.        AddToPlaylist   \n",
       "4965        Is it going to get windy today in Tunisia?          GetWeather   \n",
       "\n",
       "       target                                processed_text  \n",
       "10083       5                        play game piety street  \n",
       "4872        2                             be chilly curacao  \n",
       "447         0  add dean martin track metal xplorer playlist  \n",
       "1791        0                 add tune soft rock   playlist  \n",
       "4965        2                     be go windy today tunisia  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(data_train['processed_text'])\n",
    "X_test = tfidf.transform(data_test['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12707x10350 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 69723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistric regression\n",
    "\n",
    "Это алгоритм классификации (несмотря на слово \"регрессия\" в его названии). Он линейный, то есть, пытается разделить объекты в пространстве признаков с помощью гиперплоскостей.\n",
    "\n",
    "Тут мы тоже воспользуемся готовой реализацией. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['target'].values\n",
    "y_test = data_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', multi_class='ovr', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем качество на тесте\n",
    "\n",
    "Метрик качества существует довольно много. Самая простая -- accuracy (просто доля правильных ответов). \n",
    "\n",
    "Эта метрика обладает серьезным недостатком: если бы у нас было 99% объектов первого класса и 1% объектов второго, и модель бы всегда предсказывала только первый класс (то есть, вела себя абсолютно неадекватно), то метрика accuracy была бы равно 0.99\n",
    "\n",
    "\n",
    "Но с другой стороный, значения этой метрики проще всего интерпретировать. Да и у нас в выборке объектов разных классов приблизительно поровну, поэтому здесь использование метрики accuracy оправдано. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9694680516210261\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy = {(y_pred == y_test).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy = 0.969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Более продвинутый вариант: ELMO\n",
    "\n",
    "Далеко не всегда tf-idf себя так хорошо показывает. Да и точность 0.97 нас может по каким-то причинам не устроить. \n",
    "\n",
    "Хочется чего-то получше. Решение есть! Эмбеддинги. \n",
    "\n",
    "Эмбеддингами называют любые преобразования входных данных в числовые вектора посредством нейронных сетей. Самые простые эмбеддинги слов -- это Word2Vec. Они хорошо преобразуют слова в вектора (при этом смысл слов соотносится с операциями над векторами \"король - мужчина + женщина = королева\"), но не умеют учитывать контекст слов. Посколько в датасете есть много конструкций из нескольких слов, то лучше бы взять что-то, умеющее работать с контекстом. Например, ELMO.\n",
    "\n",
    "\n",
    "Мы воспользуемся предобученной моделью от авторов ELMO и их же реализацией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\n",
    "# !wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментируйте эти строки, если не хотите использовать видеокарту для расчетов\n",
    "# Если у вас нет возможности считать на видеокарте, то раскомментировать необязательно\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda')  # если доступна видеокарта, то будем использовать ее, иначе -- считать на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " elmo_2x4096_512_2048cnn_2xhighway_options.json\r\n",
      " elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\r\n",
      "'intent classification (copy).ipynb'\r\n",
      "'intent classification.ipynb'\r\n",
      " intents_conda_requirements.txt\r\n",
      " intents_pip_requirements.txt\r\n",
      " train.csv\r\n",
      " train.csv.1\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/27/2020 21:17:59 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "elmo = Elmo(\n",
    "    options_file='elmo_2x4096_512_2048cnn_2xhighway_options.json',\n",
    "    weight_file='elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5',\n",
    "    num_output_representations=1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo_representations': [tensor([[[-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "           [-0.0000, -0.0000,  0.1639,  ..., -0.5736,  0.9779,  0.0000],\n",
       "           [ 0.0399,  0.4843,  0.0000,  ...,  0.5934, -0.0000, -0.0640],\n",
       "           [-1.9126,  0.0000,  0.0000,  ...,  0.4616,  0.3698,  0.0000]],\n",
       "  \n",
       "          [[ 0.7848, -0.0000,  0.7963,  ...,  0.0000,  0.0000, -0.1783],\n",
       "           [-0.0000, -0.0000,  0.3812,  ...,  0.0000,  0.0000,  1.3101],\n",
       "           [-0.4574,  0.0000,  0.0000,  ...,  0.0000, -0.1770,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "         device='cuda:0', grad_fn=<DropoutBackward>)],\n",
       " 'mask': tensor([[1, 1, 1, 1],\n",
       "         [1, 1, 1, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo(batch_to_ids(\n",
    "    ['this is a test'.split(), \n",
    "     'another test sentence'.split()]).to(device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получаем эмбеддинги отдельно для каждого слова. А нам нужны эмбеддинги предложения в целом. \n",
    "\n",
    "Самый простой способ -- усреднить эмбеддинги слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизуем тексты датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(text):\n",
    "    tokenized_text = [token.text for token in spacy_parser(text)]\n",
    "    vectorized_text = batch_to_ids([tokenized_text]).to(device)\n",
    "    with torch.no_grad():  # мы не обучаем ELMO, соответственно, указываем, что градиенты нам не нужны\n",
    "        elmo_word_embeddings = elmo(vectorized_text)['elmo_representations'][0].squeeze().cpu().numpy()\n",
    "    elmo_text_embeddings = elmo_word_embeddings.mean(axis=0)\n",
    "    \n",
    "    return elmo_text_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем эмбеддинги фраз из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_elmo_embeddings_for_dataset(df):\n",
    "    texts = df['text'].values\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in tqdm(texts):\n",
    "        elmo_text_embeddings = get_text_embeddings(text)\n",
    "        embeddings.append(elmo_text_embeddings)\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f82f9554f74c9a8f357623e668456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3065a53e61054a57a36f9d986f6de9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_elmo = get_elmo_embeddings_for_dataset(data_train)\n",
    "X_test_elmo = get_elmo_embeddings_for_dataset(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_elmo, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замеряем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9779666351904313\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_elmo)\n",
    "\n",
    "print(f'Accuracy = {(y_pred == y_test).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy = 0.978\n",
    "\n",
    "Значение может немного отличаться, это особенности работы самой ELMO, связанные с сохранением скрытых состояний LSTM-слоёв и их перенос в следующие запуски. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 [intent classification]",
   "language": "python",
   "name": "demo_intents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
